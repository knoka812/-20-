import os
import gradio as gr
from openai import OpenAI
import time

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    api_key="å¡«å†™è‡ªå·±çš„å¯†é’¥å“¦~",
    base_url="https://aistudio.baidu.com/llm/lmapi/v3"
)

# æ¸¸æˆçŠ¶æ€
class GameState:
    def __init__(self):
        self.questions_asked = 0
        self.max_questions = 20
        self.game_history = []
        self.target_object = None
        self.is_game_over = False
        self.current_question = None
        self.is_game_started = False
        self.ai_score = 0
        self.human_score = 0

game_state = GameState()

def stream_response(response, history_text):
    """æµå¼è¾“å‡ºå“åº”"""
    full_response = ""
    for chunk in response:
        if chunk.choices[0].delta.content:
            full_response += chunk.choices[0].delta.content
            yield full_response, history_text
    return full_response, history_text

def set_target_object(target):
    """è®¾ç½®ç›®æ ‡ç‰©ä½“å¹¶å¼€å§‹æ¸¸æˆ"""
    if not target.strip():
        return "è¯·è¾“å…¥ç›®æ ‡ç‰©ä½“ï¼", "", "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""
    
    game_state.target_object = target.strip()
    game_state.is_game_started = True
    game_state.questions_asked = 0
    game_state.game_history = []
    game_state.is_game_over = False
    game_state.current_question = None
    
    # è®©AIæå‡ºç¬¬ä¸€ä¸ªé—®é¢˜
    prompt = """ä½ æ­£åœ¨ç©20é—®æ¸¸æˆã€‚è¯·æå‡ºç¬¬ä¸€ä¸ªé—®é¢˜æ¥çŒœæµ‹ç©å®¶å¿ƒä¸­çš„ç‰©ä½“ã€‚
é—®é¢˜åº”è¯¥æ˜¯ä¸€ä¸ªç®€å•çš„"æ˜¯/å¦"é—®é¢˜ï¼Œæ¯”å¦‚"å®ƒæ˜¯æ´»ç‰©å—ï¼Ÿ"ã€"å®ƒæ¯”æ±½è½¦å¤§å—ï¼Ÿ"ç­‰ã€‚
è¯·å…ˆæ€è€ƒä¸€ä¸‹ï¼Œç„¶ååªè¾“å‡ºé—®é¢˜ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""
    
    try:
        yield "æ¸¸æˆå¼€å§‹ï¼", "\n".join(game_state.game_history), "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", "AIæ­£åœ¨æ€è€ƒç¬¬ä¸€ä¸ªé—®é¢˜..."
        
        response = client.chat.completions.create(
            model="ernie-x1-turbo-32k",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=100,
            stream=True
        )
        
        first_question = ""
        thinking_process = "AIæ­£åœ¨æ€è€ƒç¬¬ä¸€ä¸ªé—®é¢˜...\n\n"
        for chunk in response:
            if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                thinking_process += chunk.choices[0].delta.reasoning_content
                yield "æ¸¸æˆå¼€å§‹ï¼", "\n".join(game_state.game_history), "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process
            if chunk.choices[0].delta.content:
                first_question += chunk.choices[0].delta.content
        
        game_state.current_question = first_question.strip()
        game_state.game_history.append(f"AIé—®é¢˜ {game_state.questions_asked + 1}: {first_question.strip()}")
        yield f"æ¸¸æˆå¼€å§‹ï¼\nAIçš„ç¬¬ä¸€ä¸ªé—®é¢˜ï¼š{first_question.strip()}", "\n".join(game_state.game_history), "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process + "\n\næ€è€ƒå®Œæˆï¼"
    except Exception as e:
        yield f"å‘ç”Ÿé”™è¯¯: {str(e)}", "", "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""

def answer_question(answer):
    """å¤„ç†ç©å®¶çš„å›ç­”"""
    if not game_state.is_game_started:
        return "è¯·å…ˆè®¾ç½®ç›®æ ‡ç‰©ä½“ï¼", "", "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""
    
    if game_state.is_game_over:
        return "æ¸¸æˆå·²ç»“æŸï¼Œè¯·å¼€å§‹æ–°æ¸¸æˆï¼", "", "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""
    
    if not answer.strip():
        return "è¯·è¾“å…¥ä½ çš„å›ç­”ï¼", "", "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""
    
    # è®°å½•ç©å®¶çš„å›ç­”
    game_state.game_history.append(f"ç©å®¶å›ç­”: {answer}")
    game_state.questions_asked += 1
    
    # å¦‚æœæ˜¯æœ€åä¸€è½®ï¼Œè®©AIè¿›è¡Œæœ€ç»ˆçŒœæµ‹
    if game_state.questions_asked >= game_state.max_questions:
        game_state.is_game_over = True
        
        # è®©AIè¿›è¡Œæœ€ç»ˆçŒœæµ‹
        guess_prompt = f"""åŸºäºä¹‹å‰çš„å¯¹è¯ï¼š
{chr(10).join(game_state.game_history)}

è¿™æ˜¯æœ€åä¸€è½®äº†ï¼Œè¯·æ ¹æ®æ‰€æœ‰ä¿¡æ¯ï¼Œç»™å‡ºä½ çš„æœ€ç»ˆçŒœæµ‹ã€‚
è¯·å…ˆåˆ†æä¸€ä¸‹å·²æœ‰çš„ä¿¡æ¯ï¼Œç„¶åç»™å‡ºä½ çš„çŒœæµ‹ã€‚
åªè¾“å‡ºä¸€ä¸ªå…·ä½“çš„ç‰©ä½“åç§°ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""
        
        try:
            yield "æ¸¸æˆå³å°†ç»“æŸ...", "\n".join(game_state.game_history), "", "20/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", "AIæ­£åœ¨åˆ†ææ‰€æœ‰ä¿¡æ¯å¹¶åšå‡ºæœ€ç»ˆçŒœæµ‹..."
            
            guess_response = client.chat.completions.create(
                model="ernie-x1-turbo-32k",
                messages=[{"role": "user", "content": guess_prompt}],
                temperature=0.7,
                max_tokens=50,
                stream=True
            )
            
            guess = ""
            thinking_process = "AIæ­£åœ¨åˆ†ææ‰€æœ‰ä¿¡æ¯å¹¶åšå‡ºæœ€ç»ˆçŒœæµ‹...\n\n"
            for chunk in guess_response:
                if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                    thinking_process += chunk.choices[0].delta.reasoning_content
                    yield "æ¸¸æˆå³å°†ç»“æŸ...", "\n".join(game_state.game_history), "", "20/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process
                if chunk.choices[0].delta.content:
                    guess += chunk.choices[0].delta.content
            
            guess = guess.strip()
            game_state.game_history.append(f"AIæœ€ç»ˆçŒœæµ‹: {guess}")
            
            # åˆ¤æ–­AIçš„çŒœæµ‹æ˜¯å¦æ­£ç¡®
            if guess.lower().strip() == game_state.target_object.lower().strip():
                game_state.ai_score += 1
                result = f"AIçŒœå¯¹äº†ï¼ç›®æ ‡ç‰©ä½“å°±æ˜¯ï¼š{game_state.target_object}\nAIå¾—1åˆ†ï¼"
            else:
                game_state.human_score += 1
                result = f"AIçŒœé”™äº†ï¼ç›®æ ‡ç‰©ä½“æ˜¯ï¼š{game_state.target_object}\näººç±»å¾—1åˆ†ï¼"
            
            history_text = "\n".join(game_state.game_history)
            yield result, history_text, "", "20/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process + "\n\næ€è€ƒå®Œæˆï¼"
            return
        except Exception as e:
            yield f"å‘ç”Ÿé”™è¯¯: {str(e)}", "", "", "20/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""
            return
    
    # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œè®©AIç»§ç»­æé—®
    next_prompt = f"""åŸºäºä¹‹å‰çš„å¯¹è¯ï¼š
{chr(10).join(game_state.game_history)}

è¯·åˆ†æè¿™äº›é—®ç­”ï¼Œæå‡ºä¸‹ä¸€ä¸ªé—®é¢˜æ¥çŒœæµ‹ç©å®¶å¿ƒä¸­çš„ç‰©ä½“ã€‚
é—®é¢˜åº”è¯¥æ˜¯ä¸€ä¸ªç®€å•çš„"æ˜¯/å¦"é—®é¢˜ï¼Œè¦åŸºäºä¹‹å‰çš„å›ç­”æ¥ç¼©å°èŒƒå›´ï¼Œä½†ä¹Ÿè¦æ³¨æ„ï¼Œæœ‰æ—¶ç©å®¶å¹¶ä¸çŸ¥é“è¿™ä¸ªç‰©ä½“åº”è¯¥é€‰æ˜¯è¿˜æ˜¯å¦ï¼Œå¯èƒ½ä¼šå‡ºç°å›ç­”é”™è¯¯ï¼Œå› æ­¤è¦è€ƒè™‘è¿™ç§æƒ…å†µã€‚
è¯·å…ˆæ€è€ƒä¸€ä¸‹ï¼Œç„¶ååªè¾“å‡ºé—®é¢˜ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""
    
    try:
        yield "AIæ­£åœ¨æ€è€ƒ...", "\n".join(game_state.game_history), "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", f"AIæ­£åœ¨åˆ†æç¬¬{game_state.questions_asked}è½®çš„å›ç­”å¹¶æ€è€ƒä¸‹ä¸€ä¸ªé—®é¢˜..."
        
        next_response = client.chat.completions.create(
            model="ernie-x1-turbo-32k",
            messages=[{"role": "user", "content": next_prompt}],
            temperature=0.7,
            max_tokens=100,
            stream=True
        )
        
        next_question = ""
        thinking_process = f"AIæ­£åœ¨åˆ†æç¬¬{game_state.questions_asked}è½®çš„å›ç­”å¹¶æ€è€ƒä¸‹ä¸€ä¸ªé—®é¢˜...\n\n"
        for chunk in next_response:
            if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                thinking_process += chunk.choices[0].delta.reasoning_content
                yield "AIæ­£åœ¨æ€è€ƒ...", "\n".join(game_state.game_history), "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process
            if chunk.choices[0].delta.content:
                next_question += chunk.choices[0].delta.content
        
        next_question = next_question.strip()
        game_state.current_question = next_question
        game_state.game_history.append(f"AIé—®é¢˜ {game_state.questions_asked + 1}: {next_question}")
        
        history_text = "\n".join(game_state.game_history)
        yield f"AIçš„é—®é¢˜ {game_state.questions_asked + 1}/20: {next_question}", history_text, "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", thinking_process + "\n\næ€è€ƒå®Œæˆï¼"
    except Exception as e:
        yield f"å‘ç”Ÿé”™è¯¯: {str(e)}", "", "", f"{game_state.questions_asked}/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", ""

def reset_game():
    """é‡ç½®æ¸¸æˆ"""
    game_state.questions_asked = 0
    game_state.game_history = []
    game_state.is_game_over = False
    game_state.target_object = None
    game_state.current_question = None
    game_state.is_game_started = False
    return "æ¸¸æˆå·²é‡ç½®ï¼è¯·è®¾ç½®æ–°çš„ç›®æ ‡ç‰©ä½“ã€‚", "", "", "0/20", f"AI: {game_state.ai_score} - äººç±»: {game_state.human_score}", "æ¸¸æˆå·²é‡ç½®ï¼Œç­‰å¾…å¼€å§‹æ–°æ¸¸æˆ..."

# è‡ªå®šä¹‰CSSæ ·å¼
custom_css = """
.round-counter {
    font-size: 24px !important;
    font-weight: bold !important;
    color: #4a90e2 !important;
    padding: 10px 20px !important;
    background-color: #f5f5f5 !important;
    border-radius: 10px !important;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
    margin-left: auto !important;
}

.score-counter {
    font-size: 20px !important;
    font-weight: bold !important;
    color: #2c3e50 !important;
    padding: 8px 16px !important;
    background-color: #ecf0f1 !important;
    border-radius: 8px !important;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
    margin-left: 20px !important;
}

.thinking {
    color: #666 !important;
    font-style: italic !important;
}

.ai-thinking {
    font-family: 'Courier New', monospace !important;
    background-color: #f8f9fa !important;
    padding: 15px !important;
    border-radius: 8px !important;
    border-left: 4px solid #4a90e2 !important;
    margin: 10px 0 !important;
    white-space: pre-wrap !important;
    font-size: 14px !important;
    line-height: 1.5 !important;
}
"""

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    with gr.Row():
        gr.Markdown("# ğŸ® çŸ¥ä½ æ‰€æƒ³")
        round_counter = gr.Markdown("0/20", elem_classes=["round-counter"])
        score_counter = gr.Markdown("AI: 0 - äººç±»: 0", elem_classes=["score-counter"])
    gr.Markdown("### 20ä¸ªé—®é¢˜ï¼ŒçŒœä¸­ä½ æ‰€æƒ³çš„ä¸œè¥¿ï¼Œæ¥æŒ‘æˆ˜ä¸€ä¸‹å§ï¼")
    
    with gr.Row():
        with gr.Column(scale=1):
            target_input = gr.Textbox(
                label="è¾“å…¥ä½ æƒ³è®©AIçŒœçš„ç‰©ä½“",
                placeholder="ä¾‹å¦‚ï¼šé•¿é¢ˆé¹¿",
                lines=2
            )
            set_target_button = gr.Button("è®¾ç½®ç›®æ ‡ç‰©ä½“", variant="primary")
        with gr.Column(scale=1):
            answer_input = gr.Textbox(
                label="å›ç­”AIçš„é—®é¢˜",
                placeholder="è¾“å…¥ï¼šæ˜¯ã€å¦ã€æˆ–ä¸çŸ¥é“",
                lines=2
            )
            answer_button = gr.Button("å›ç­”", variant="primary")
    

    with gr.Row():
        reset_button = gr.Button("å¼€å§‹æ–°æ¸¸æˆ", variant="stop")
    
    with gr.Row():
        ai_thinking = gr.Textbox(
            label="AIæ€è€ƒè¿‡ç¨‹",
            lines=5,
            elem_classes=["ai-thinking"],
            interactive=False
        )
    
    with gr.Row():
        output = gr.Textbox(label="æ¸¸æˆçŠ¶æ€", lines=10)
        history = gr.Textbox(label="æ¸¸æˆå†å²", lines=10)
        error = gr.Textbox(label="é”™è¯¯ä¿¡æ¯", lines=10)
    
    # è®¾ç½®äº‹ä»¶å¤„ç†
    set_target_button.click(
        set_target_object,
        inputs=[target_input],
        outputs=[output, history, error, round_counter, score_counter, ai_thinking],
        queue=True
    )
    
    answer_button.click(
        answer_question,
        inputs=[answer_input],
        outputs=[output, history, error, round_counter, score_counter, ai_thinking],
        queue=True
    )
    
    reset_button.click(
        reset_game,
        outputs=[output, history, error, round_counter, score_counter, ai_thinking]
    )

if __name__ == "__main__":
    demo.queue().launch() 